{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model\n",
    "%load_ext lab_black\n",
    "# nb_black if running in jupyter\n",
    "%load_ext autoreload\n",
    "# automatically reload python modules if there are changes in the\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\r\n",
    "\r\n",
    "> In this notebook you create and test a Python class to hold your machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***input***: toy dataset from data-notebook\n",
    "\n",
    "***output***: TFF model for predicting customer paths \n",
    "\n",
    "***description:***\n",
    "\n",
    "Model for simulating federated learning on predicting customer paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow_federated_nightly also bring in tf_nightly, which\n",
    "# can causes a duplicate tensorboard install, leading to errors.\n",
    "#!pip uninstall --yes tensorboard tb-nightly\n",
    "\n",
    "#!pip install --quiet --upgrade tensorflow-federated-nightly\n",
    "#!pip install --quiet --upgrade nest-asyncio\n",
    "#!pip install --quiet --upgrade tb-nightly  # or tensorboard, but not both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "b'Hello, World!'"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "train_test_client_split = tff.simulation.datasets.ClientData.train_test_client_split\n",
    "\n",
    "tff.federated_computation(lambda: \"Hello, World!\")()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyarrow import feather\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_federated_customer_path.data import create_tff_client_data_from_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define notebook parameters\r\n",
    "\r\n",
    "Remember, only simple assignments here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is tagged with 'parameters'\n",
    "seed = 0\n",
    "data_filepath = \"data/preprocessed_data/data.f\"\n",
    "test_split = 0.2\n",
    "toy_size = 0.1\n",
    "\n",
    "NUM_CLIENTS = 10\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 20\n",
    "SHUFFLE_BUFFER = 100\n",
    "PREFETCH_BUFFER = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make immediate derivations from the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import toy data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>client_id</th>\n      <th>x</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>[1, 0, 0, 0, 0, 0, 0, 0]</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>[0, 0, 0, 0, 0, 0, 1, 0]</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>[0, 0, 0, 0, 0, 0, 1, 0]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>83637</th>\n      <td>9999</td>\n      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>83638</th>\n      <td>9999</td>\n      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>83639</th>\n      <td>9999</td>\n      <td>[0, 0, 0, 0, 1, 0, 0, 0]</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>83640</th>\n      <td>9999</td>\n      <td>[0, 0, 0, 1, 0, 0, 0, 0]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>83641</th>\n      <td>9999</td>\n      <td>[0, 1, 0, 0, 0, 0, 0, 0]</td>\n      <td>8</td>\n    </tr>\n  </tbody>\n</table>\n<p>83642 rows Ã— 3 columns</p>\n</div>",
      "text/plain": "       client_id                         x  y\n0              0  [1, 0, 0, 0, 0, 0, 0, 0]  8\n1              1  [1, 0, 0, 0, 0, 0, 0, 0]  6\n2              1  [0, 0, 0, 0, 0, 0, 1, 0]  6\n3              1  [0, 0, 0, 0, 0, 0, 1, 0]  1\n4              1  [0, 1, 0, 0, 0, 0, 0, 0]  2\n...          ...                       ... ..\n83637       9999  [0, 1, 0, 0, 0, 0, 0, 0]  1\n83638       9999  [0, 1, 0, 0, 0, 0, 0, 0]  4\n83639       9999  [0, 0, 0, 0, 1, 0, 0, 0]  3\n83640       9999  [0, 0, 0, 1, 0, 0, 0, 0]  1\n83641       9999  [0, 1, 0, 0, 0, 0, 0, 0]  8\n\n[83642 rows x 3 columns]"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = feather.read_feather(data_filepath)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert into tff ClientData (training + testing datasets):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_data = create_tff_client_data_from_df(df, sample_size=0.1)\n",
    "train_data, test_data = train_test_client_split(\n",
    "    client_data, int(toy_size * df.client_id.nunique() * test_split)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "751"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.client_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "200"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data.client_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear dataframe as no longer needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain the math behind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore with simple scripts before constructing the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('x', TensorSpec(shape=(None, 8), dtype=tf.uint8, name=None)),\n             ('y', TensorSpec(shape=(None,), dtype=tf.int32, name=None))])"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.element_type_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0]], dtype=uint8)"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_dataset = train_data.create_tf_dataset_for_client(train_data.client_ids[0])\n",
    "\n",
    "example_element = next(iter(example_dataset))\n",
    "\n",
    "example_dataset.element_spec\n",
    "example_element[\"x\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1],\n       [1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1],\n       [1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 1, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 1, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0, 0, 1],\n       [0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0],\n       [0, 0, 1, 0, 0, 0, 0, 0]], dtype=uint8)"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_element = next(iter(example_dataset))\n",
    "\n",
    "example_dataset.element_spec\n",
    "example_element[\"x\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define you ML model class\n",
    "\n",
    "Remember that you can also create base class and subclasses to utilize heritance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "    return tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(64, kernel_initializer=\"zeros\", input_shape=(8,)),\n",
    "            tf.keras.layers.Softmax(),  # tf.keras.layers.Dense(8, activation=\"Softmax\"),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    # We _must_ create a new model here, and _not_ capture it from an external\n",
    "    # scope. TFF will call this within different graph contexts.\n",
    "    keras_model = create_keras_model()\n",
    "    return tff.learning.from_keras_model(\n",
    "        keras_model,\n",
    "        input_spec=collections.OrderedDict(\n",
    "            x=example_dataset.element_spec[\"x\"],\n",
    "            y=example_dataset.element_spec[\"y\"],\n",
    "        ),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From /anaconda/envs/federated_customer_path/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:59: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.compat.v1.graph_util.extract_sub_graph`\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "WARNING:tensorflow:From /anaconda/envs/federated_customer_path/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/compiler/tensorflow_computation_transformations.py:59: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse `tf.compat.v1.graph_util.extract_sub_graph`\n"
    }
   ],
   "source": [
    "state = iterative_process.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterable = train_data.create_tf_dataset_for_client(train_data.client_ids[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('x',\n              <tf.Tensor: shape=(15, 8), dtype=uint8, numpy=\n              array([[0, 0, 1, 0, 0, 0, 0, 0],\n                     [0, 0, 0, 0, 1, 0, 0, 0],\n                     [0, 0, 0, 0, 1, 0, 0, 0],\n                     [0, 0, 1, 0, 0, 0, 0, 0],\n                     [1, 0, 0, 0, 0, 0, 0, 0],\n                     [0, 0, 1, 0, 0, 0, 0, 0],\n                     [0, 0, 1, 0, 0, 0, 0, 0],\n                     [1, 0, 0, 0, 0, 0, 0, 0],\n                     [1, 0, 0, 0, 0, 0, 0, 0],\n                     [0, 0, 0, 0, 1, 0, 0, 0],\n                     [0, 0, 0, 0, 1, 0, 0, 0],\n                     [0, 0, 1, 0, 0, 0, 0, 0],\n                     [1, 0, 0, 0, 0, 0, 0, 0],\n                     [1, 0, 0, 0, 0, 0, 0, 0],\n                     [0, 0, 0, 0, 1, 0, 0, 0]], dtype=uint8)>),\n             ('y',\n              <tf.Tensor: shape=(15,), dtype=int32, numpy=array([4, 8, 8, 4, 2, 4, 4, 2, 2, 8, 8, 4, 2, 2, 8], dtype=int32)>)])"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = next(iter(iterable))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<PrefetchDataset shapes: OrderedDict([(x, (None, 8)), (y, (None,))]), types: OrderedDict([(x, tf.uint8), (y, tf.int32)])>"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.create_tf_dataset_for_client(train_data.client_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "751"
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.client_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_client_data(client_data, batch_size=BATCH_SIZE):\n",
    "    batch = [\n",
    "        client_data.create_tf_dataset_for_client(client_data.client_ids[idx])\n",
    "        for idx in np.random.choice(\n",
    "            np.arange(len(client_data.client_ids)), size=BATCH_SIZE\n",
    "        )\n",
    "    ]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.18596491), ('loss', 4.1560683)])), ('stat', OrderedDict([('num_examples', 570)]))])\n"
    }
   ],
   "source": [
    "pass_data = [\n",
    "    train_data.create_tf_dataset_for_client(train_data.client_ids[0]),\n",
    "    train_data.create_tf_dataset_for_client(train_data.client_ids[1]),\n",
    "]\n",
    "# pass_data = [next(iter(iterable)), next(iter(iterable))]\n",
    "state, metrics = iterative_process.next(state, batch_client_data(train_data))\n",
    "\n",
    "print(\"round  1, metrics={}\".format(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "round  0, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.23571429), ('loss', 4.1483927)])), ('stat', OrderedDict([('num_examples', 700)]))])\nround  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.17190082), ('loss', 4.1426134)])), ('stat', OrderedDict([('num_examples', 605)]))])\nround  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.22053571), ('loss', 4.1307726)])), ('stat', OrderedDict([('num_examples', 1120)]))])\nround  3, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.16995305), ('loss', 4.118602)])), ('stat', OrderedDict([('num_examples', 1065)]))])\nround  4, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.2244898), ('loss', 4.1057115)])), ('stat', OrderedDict([('num_examples', 980)]))])\nround  5, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.22637363), ('loss', 4.0951114)])), ('stat', OrderedDict([('num_examples', 910)]))])\nround  6, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.19224806), ('loss', 4.0880804)])), ('stat', OrderedDict([('num_examples', 645)]))])\nround  7, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.19849624), ('loss', 4.0826674)])), ('stat', OrderedDict([('num_examples', 665)]))])\nround  8, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.20942408), ('loss', 4.0694637)])), ('stat', OrderedDict([('num_examples', 955)]))])\nround  9, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.18013245), ('loss', 4.0592923)])), ('stat', OrderedDict([('num_examples', 755)]))])\n"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    state, metrics = iterative_process.next(state, batch_client_data(train_data))\n",
    "\n",
    "    print(\"round  {}, metrics={}\".format(i, metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit test\n",
    "\n",
    "Unit test your class or classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize model behaviour with toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output of this notebook\r\n",
    "\r\n",
    "The result of this notebook is a collection methods ready for evaluation with the real data.\r\n",
    "\r\n",
    "You should export classes and functions to `model.py` with `# nbdev_build_lib` (workflows will do this automatically)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can move on to loss notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (fcp)",
   "language": "python",
   "name": "federated_customer_path"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
